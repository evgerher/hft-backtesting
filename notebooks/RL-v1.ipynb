{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/hft-backtesting\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from collections import deque, namedtuple, defaultdict\n",
    "from typing import Union, List, Dict, Tuple, NamedTuple, Deque, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from hft.utils import logger\n",
    "logger.to_file = True\n",
    "logger.fmt_string = \"%(message)s\"\n",
    "\n",
    "from hft.backtesting.backtest import BacktestOnSample\n",
    "from hft.backtesting.data import OrderStatus, OrderRequest\n",
    "from hft.backtesting.readers import OrderbookReader\n",
    "from hft.backtesting.strategy import Strategy\n",
    "from hft.units.metrics.composite import Lipton\n",
    "from hft.units.metrics.instant import VWAP_volume, LiquiditySpectrum, HayashiYoshido\n",
    "from hft.units.metrics.time import TradeMetric\n",
    "from hft.utils.data import Trade, OrderBook\n",
    "from hft.backtesting.output import make_plot_orderbook_trade, Output, SimulatedOrdersOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling DQN \n",
    "\n",
    "Dueling DQN implementation with target network implementation on pytorch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class DuelingDQN(nn.Module):\n",
    "  def __init__(self, input_dim: int, output_dim: int):\n",
    "    super().__init__()\n",
    "    self.input_dim: int = input_dim\n",
    "    self.output_dim: int = output_dim\n",
    "\n",
    "    self.feature_layer = nn.Sequential(\n",
    "      nn.Linear(input_dim, 128),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 128),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.value_stream = nn.Sequential(\n",
    "      nn.Linear(128, 128),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 1)\n",
    "    )\n",
    "\n",
    "    self.advantage_stream = nn.Sequential(\n",
    "      nn.Linear(128, 128),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, self.output_dim)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.feature_layer(x)\n",
    "    value = self.value_stream(x)\n",
    "    adv = self.advantage_stream(x)\n",
    "    qvals = value + (adv - adv.mean())\n",
    "    return value, adv, qvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision condition\n",
    "\n",
    "Class defines moments when model will make actions.  \n",
    "Model's reaction on __each__ snapshot update would be incredibly expensive, thus it reacts _volume-based_.  \n",
    "\n",
    "## Agent\n",
    "\n",
    "Class stores inner operation for RL:\n",
    "\n",
    "- Stores _replay buffer_  \n",
    "- Generates actions via model or random  \n",
    "- Evaluates rewards and updates models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', 'obs ps action next_obs next_ps meta done')\n",
    "\n",
    "class DecisionCondition:\n",
    "  def __init__(self, mu: float, std: float = 1.0):\n",
    "    assert mu > 0\n",
    "    assert std > 0\n",
    "\n",
    "    self.mu = mu\n",
    "    self.std = std\n",
    "    self.volume_condition: float = random.gauss(mu, std)\n",
    "    self.reset()\n",
    "\n",
    "  def __call__(self, is_trade: bool, event: Union[Trade, OrderBook]):\n",
    "    if is_trade and event.symbol == 'XBTUSD':\n",
    "      self.volume += event.volume\n",
    "      if self.volume > self.volume_condition:\n",
    "        self.volume %= self.volume_condition\n",
    "        self.volume_condition = random.gauss(self.mu, self.std)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "  def reset(self):\n",
    "    self.volume = 0.0\n",
    "\n",
    "class Agent:\n",
    "  def __init__(self, model: DuelingDQN, target: DuelingDQN,\n",
    "               condition: DecisionCondition,\n",
    "               gamma=0.95, lr=1e-3,\n",
    "               update_each: int = 3,\n",
    "               buffer_size: int = 30000, batch_size=1024):\n",
    "    self._replay_buffer: Deque[State] = deque(maxlen=buffer_size)\n",
    "    self._batch_size: int = batch_size\n",
    "    self.condition: DecisionCondition = condition\n",
    "    self._model: DuelingDQN = model\n",
    "    self._target: DuelingDQN = target\n",
    "    self.end_episode_states: List = []\n",
    "    self.episode_files: List[Tuple[str, str]] = []\n",
    "\n",
    "    self.EPS_START = 0.9\n",
    "    self.EPS_END = 0.1\n",
    "    self.EPS_DECAY = 500\n",
    "\n",
    "    self.gamma = gamma\n",
    "    self.loss = torch.nn.SmoothL1Loss()\n",
    "    self.optimizer = torch.optim.Adam(self._model.parameters(), lr=lr, amsgrad=True)\n",
    "\n",
    "    self._update_each = update_each\n",
    "    self.episode_counter = 0\n",
    "    self._evaluate = False\n",
    "    \n",
    "    self.no_action_event = deque(maxlen=20)\n",
    "    self.reset_state()\n",
    "    \n",
    "  def eval(self):\n",
    "    self._evaluate = True\n",
    "    \n",
    "  def evaluate(self):\n",
    "    return self._evaluate\n",
    "\n",
    "  def store_no_action(self, ts, price):\n",
    "    self.no_action_event[0].append((ts, price))\n",
    "\n",
    "  def episode_results(self) -> pd.DataFrame:\n",
    "    fnames, states = agent.episode_files, agent.end_episode_states\n",
    "    states = [t[0].tolist() + [t[1]] for t in states]\n",
    "    episodes = [list(t[0]) + t[1] for t in zip(fnames, states)]\n",
    "    res = pd.DataFrame(episodes, columns=['ob_file', 'tr_file', 'usd', 'xbt', 'eth', 'xbt_price'])\n",
    "    return res\n",
    "\n",
    "  def reset_state(self):\n",
    "    self.obs = None\n",
    "    self.action = None\n",
    "    self.ps = None\n",
    "    self.episode_counter += 1\n",
    "    self.condition.reset()\n",
    "    self.no_action_event.appendleft([])\n",
    "\n",
    "\n",
    "    # reload weights\n",
    "    if not self.evaluate():\n",
    "        state = self._model.state_dict()\n",
    "        if (self.episode_counter + 1) % self._update_each == 0:\n",
    "            self._target.load_state_dict(state)\n",
    "            torch.save(state, f'models/model-{self.episode_counter}.pth')\n",
    "        torch.save(state, f'model-latest.pth')\n",
    "\n",
    "  def get_reward(self, prev_v: torch.Tensor, v: torch.Tensor,\n",
    "                 prev_ps: torch.Tensor, ps: torch.Tensor,\n",
    "                 tau: torch.Tensor, a=0.1, b=1. / 1000,\n",
    "                 offset=1.1, scale=0.1):\n",
    "    vv = a * (v - prev_v).squeeze(1)\n",
    "\n",
    "    state_delta = torch.abs(prev_ps) - torch.abs(ps)  # todo: updated here, react negatively on accumulation of assets\n",
    "    pos = (torch.exp(b * tau) * state_delta)  # todo: updated here, instead of sign, use delta\n",
    "\n",
    "    accumulation_penalty = -torch.exp(torch.abs(ps) * scale) + offset\n",
    "\n",
    "    # a(V_t - V_{t-1}) + e^{b*tau} * sgn(|i_t| - |i_{t-1}|)\n",
    "    return vv + pos + accumulation_penalty\n",
    "\n",
    "  def get_terminal_reward(self, terminal_ps, terminal_prices, alpha=3.0, scale=4.0, shift=8.0):\n",
    "    inbalance = (terminal_ps[:, 0] / terminal_prices - terminal_ps[:, 1])\n",
    "    return torch.exp(torch.abs(inbalance) * scale) * torch.sign(inbalance) / shift  # 0: usd, 1: xbtusd, 2: ethusd\n",
    "\n",
    "  def store_episode(self, new_obs, new_ps, meta, done, action):\n",
    "    nans = [np.isnan(t).any() for t in [new_obs, new_ps, meta, done, action]]\n",
    "    if not any(nans):\n",
    "      if self.is_initialized():\n",
    "        self._replay_buffer.append((self.obs, self.ps, self.action, new_obs, new_ps, meta, done))\n",
    "      self.obs = new_obs\n",
    "      self.ps = new_ps\n",
    "      self.action = action\n",
    "\n",
    "  def is_initialized(self):\n",
    "    return self.obs is not None  # happens after reset, first obs is missing\n",
    "\n",
    "  def get_action(self, obs):\n",
    "    eps = self.EPS_END + (self.EPS_START - self.EPS_END) * np.exp(-1. * self.episode_counter / self.EPS_DECAY)\n",
    "    if np.random.uniform(0.0, 1.0) < eps:\n",
    "      return random.randint(0, self._model.output_dim - 1)\n",
    "    with torch.no_grad(): # target net defines action\n",
    "      _, _, qvals = self._target(torch.tensor(obs, dtype=torch.float, device=device).unsqueeze(0))\n",
    "      action = torch.argmax(qvals).cpu().detach().item()\n",
    "      return action\n",
    "\n",
    "  def update(self):\n",
    "    if len(self._replay_buffer) > self._batch_size:\n",
    "      items = random.sample(self._replay_buffer, self._batch_size)\n",
    "      prev_obs, prev_ps, action, obs, ps, meta, done = zip(*items)\n",
    "      prev_obs, prev_ps, obs, ps, meta = map(lambda x: torch.tensor(x, dtype=torch.float).to(device),\n",
    "                                             [prev_obs, prev_ps, obs, ps, meta])\n",
    "      done = torch.tensor(done, dtype=torch.bool).to(device)\n",
    "      action = torch.tensor(action, dtype=torch.long).unsqueeze(1).to(device)\n",
    "\n",
    "      v, _, qvalues = self._model(prev_obs)\n",
    "      with torch.no_grad():\n",
    "        next_v, _, next_qvalues = self._target(obs[~done])\n",
    "\n",
    "        #           next_v.detach()\n",
    "        #           next_qvalues.detach()\n",
    "        #           _.detach()\n",
    "        next_qvalues = next_qvalues.max(1)[0]\n",
    "\n",
    "      rewards = torch.empty_like(done, dtype=torch.float, device=device)\n",
    "      rewards[done] = self.get_terminal_reward(ps[done], meta[done][:, 0])\n",
    "      rewards[~done] = self.get_reward(v[~done], next_v, prev_ps[~done][:, 1], ps[~done][:, 1], meta[~done][:, 1])\n",
    "      rewards = rewards.clamp(-1., 1.)  # reward clipping\n",
    "\n",
    "      qvalues = qvalues.gather(1, action).squeeze(1)\n",
    "\n",
    "      expected_q = torch.empty_like(rewards, dtype=torch.float, device=device)\n",
    "      expected_q[~done] = self.gamma * next_qvalues\n",
    "      expected_q += rewards\n",
    "\n",
    "\n",
    "      loss = self.loss(qvalues, expected_q)  # or hubert loss\n",
    "\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      for param in self._model.parameters():\n",
    "        param.grad.data.clamp_(-1., 1.)  # gradient clipping\n",
    "      self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Strategy\n",
    "\n",
    "Class wrapper for RL operations: \n",
    "\n",
    "- Provides observations, portfolio states\n",
    "- Transforms action space into orders\n",
    "- Communicates with backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLStrategy(Strategy):\n",
    "  def __init__(self, agent: Agent, simulation_end: datetime.datetime, cancels_enabled=False, **kwags):\n",
    "    super().__init__(**kwags)\n",
    "    self.agent: Agent = agent\n",
    "    self._simulation_end = simulation_end\n",
    "    self.action_space: Dict[int, Tuple[int, int]] = {\n",
    "      0:  (0, 0),\n",
    "      1:  (1, 0),\n",
    "      2:  (2, 0),\n",
    "      3:  (3, 0),\n",
    "      4:  (0, 1),\n",
    "      5:  (1, 1),\n",
    "      6:  (1, 2),\n",
    "      7:  (1, 3),\n",
    "      8:  (0, 3),\n",
    "      9:  (2, 1),\n",
    "      10: (2, 2),\n",
    "      11: (2, 3),\n",
    "      12: (0, 2),\n",
    "      13: (3, 1),\n",
    "      14: (3, 2),\n",
    "      15: (3, 3),\n",
    "      16: (4, 0),\n",
    "      17: (4, 1),\n",
    "      18: (4, 2),\n",
    "      19: (4, 3),\n",
    "      20: (4, 4),\n",
    "      21: (0, 4),\n",
    "      22: (1, 4),\n",
    "      23: (2, 4),\n",
    "      24: (3, 4),\n",
    "    }\n",
    "    self.cancels_enabled = cancels_enabled\n",
    "    self.no_action_event = []\n",
    "\n",
    "  def return_unfinished(self, statuses: List[OrderStatus], memory: Dict[str, Union[Trade, OrderBook]]):\n",
    "    obs, ps, prices = self.get_observation(memory, 0.0)\n",
    "    meta = (prices, 0.0)\n",
    "    self.agent.store_episode(obs, ps, meta, True, 0)\n",
    "    self.agent.end_episode_states.append((ps, meta[0]))  # end state and prices\n",
    "    self.agent.reset_state()\n",
    "\n",
    "    super().return_unfinished(statuses, memory)\n",
    "\n",
    "  def get_observation(self, memory, timeleft):\n",
    "    items = list(map(lambda name: self.metrics_map[name].to_numpy(), names + time_names))\n",
    "    items = [t.flatten() for t in items]\n",
    "\n",
    "    prices = self.get_prices(memory)\n",
    "    ps = self.get_state()\n",
    "    state = np.array([ps[0] / prices, ps[1]])\n",
    "\n",
    "    items += [state, timeleft]\n",
    "    items = np.concatenate(items, axis=None)\n",
    "    return items, ps, prices\n",
    "\n",
    "  def get_prices(self, memory) -> float:  # todo: refactor and use vwap\n",
    "    xbt: OrderBook = memory[('orderbook', 'XBTUSD')]\n",
    "    xbt_midprice = (xbt.ask_prices[0] + xbt.bid_prices[0]) / 2\n",
    "\n",
    "    # eth: OrderBook = memory[('orderbook', 'ETHUSD')]\n",
    "    # eth_midprice = (eth.ask_prices[0] + eth.bid_prices[0]) / 2\n",
    "\n",
    "    return xbt_midprice\n",
    "\n",
    "  def get_state(self) -> np.array:\n",
    "    return np.array(list(self.balance.values()))\n",
    "\n",
    "  def get_timeleft(self, ts: datetime.datetime) -> float:\n",
    "    return (self._simulation_end - ts).total_seconds()\n",
    "\n",
    "  def action_to_order(self, action: int, memory, ts, quantity: int) -> List[OrderRequest]:\n",
    "    offset_bid, offset_ask = self.action_space[action]\n",
    "\n",
    "    offset_bid *= 0.5  # price step is .5 dollars\n",
    "    offset_ask *= 0.5\n",
    "\n",
    "    ob: OrderBook = memory[('orderbook', 'XBTUSD')]\n",
    "    orders = []\n",
    "\n",
    "    if offset_bid >= 0:\n",
    "      orders.append(OrderRequest.create_bid(ob.bid_prices[0] - offset_bid, quantity, 'XBTUSD', ts))\n",
    "    if offset_ask >= 0:\n",
    "      orders.append(OrderRequest.create_ask(ob.ask_prices[0] + offset_ask, quantity, 'XBTUSD', ts))\n",
    "\n",
    "    return orders\n",
    "\n",
    "  def cancel_orders(self, statuses: List[OrderStatus]) -> List[OrderRequest]:\n",
    "    statuses_ids = list(map(lambda x: x.id, statuses))\n",
    "    active = self.active_orders.items()\n",
    "    active_non_present = filter(lambda x: x[0] not in statuses_ids, active)\n",
    "    return list(map(lambda x: OrderRequest.cancelOrder(x[0]), active_non_present))\n",
    "\n",
    "  def define_orders(self, row: Union[Trade, OrderBook],\n",
    "                    statuses: List[OrderStatus],\n",
    "                    memory: Dict[str, Union[Trade, OrderBook]],\n",
    "                    is_trade: bool) -> List[OrderRequest]:\n",
    "    if self.agent.condition(is_trade, row):\n",
    "      timeleft = self.get_timeleft(row.timestamp)\n",
    "      obs, ps, prices = self.get_observation(memory, timeleft)\n",
    "\n",
    "      action = self.agent.get_action(obs)\n",
    "\n",
    "      meta = (prices, timeleft)\n",
    "      self.agent.store_episode(obs, ps, meta, False, action)\n",
    "      self.agent.update()\n",
    "\n",
    "      orders = self.action_to_order(action, memory, row.timestamp, 1000)\n",
    "      if self.cancels_enabled:\n",
    "        cancels = self.cancel_orders(statuses)\n",
    "        orders += cancels\n",
    "    else:\n",
    "      orders = []\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrices: [2,3,2], [2,3,2], [2, 2], [2]\n",
    "names = ['vwap', 'liquidity-spectrum', 'hayashi-yoshido', 'lipton']\n",
    "# [2, 2], [2, 2]\n",
    "time_names = ['trade-metric-45', 'trade-metric-80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_simulation(agent: Agent, orderbook_file: str, trade_file: str,\n",
    "                    output_required: Union[bool, Output] = False, delay=5,\n",
    "                    cancels_enaled=True) -> Optional[Output]:\n",
    "\n",
    "  if isinstance(output_required, bool) and output_required:\n",
    "    output = SimulatedOrdersOutput()\n",
    "  elif isinstance(output_required, Output):\n",
    "    output = output_required\n",
    "  else:\n",
    "    output = None\n",
    "\n",
    "  vwap = VWAP_volume([int(5e5), int(1e6), int(2e6)], name='vwap', z_normalize=3000)\n",
    "  liq = LiquiditySpectrum(z_normalize=3000)\n",
    "\n",
    "  defaults = [\n",
    "    (('XBTUSD', 0), [0.0]),\n",
    "    (('XBTUSD', 1), [0.0]),\n",
    "    (('ETHUSD', 0), [0.0]),\n",
    "    (('ETHUSD', 1), [0.0]),\n",
    "  ]\n",
    "\n",
    "  trade_metric = TradeMetric(defaults, [\n",
    "    # ('quantity', lambda x: len(x)),\n",
    "    ('total', lambda trades: sum(map(lambda x: x.volume, trades)))\n",
    "  ], seconds=45, z_normalize=2000)\n",
    "  trade_metric2 = TradeMetric(defaults, [\n",
    "    # ('quantity', lambda x: len(x)),\n",
    "    ('total', lambda trades: sum(map(lambda x: x.volume, trades)))\n",
    "  ], seconds=80, z_normalize=2000)\n",
    "\n",
    "  lipton_levels = 8\n",
    "  hy = HayashiYoshido(140, True)\n",
    "  lipton = Lipton(hy.name, lipton_levels)\n",
    "\n",
    "  reader = OrderbookReader(orderbook_file, trade_file, nrows=None, is_precomputed=True)\n",
    "  end_ts = reader.get_ending_moment()\n",
    "\n",
    "  strategy = RLStrategy(agent, simulation_end=end_ts, instant_metrics=[vwap, liq], delta_metrics=[hy],\n",
    "                        time_metrics_trade=[trade_metric, trade_metric2], composite_metrics=[lipton],\n",
    "                        initial_balance=0.0, cancels_enabled=cancels_enaled)\n",
    "  backtest = BacktestOnSample(reader, strategy, output=output, delay=delay, warmup=True, stale_depth=7)\n",
    "  backtest.run()\n",
    "\n",
    "  return backtest.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_from_df(idx, info=True, savefig=False):\n",
    "    import matplotlib.patches as mpatches\n",
    "    \n",
    "    orders_side1, orders_side2 = list(outputs[idx].orders.values())\n",
    "    ob_file = res.ob_file.iloc[idx]\n",
    "    fig, axs = make_plot_orderbook_trade(ob_file, 'XBTUSD', \n",
    "                          orders_side1 + orders_side2, \n",
    "                          None,\n",
    "                          orderbook_precomputed=True, savefig=savefig)\n",
    "    \n",
    "    if info:\n",
    "        assert idx < 0 \n",
    "        ob_file, pnl, xbt, usd, price = res.loc[len(res)+idx, ['ob_file', 'pnl', 'xbt', 'usd', 'xbt_price']] \n",
    "        patches = [\n",
    "            mpatches.Patch(color='red', label=f'PNL: {pnl:.3f} USD'),\n",
    "            mpatches.Patch(color='green', label=f'Price: {price:.2f} USD'),\n",
    "            mpatches.Patch(color='blue', label=f'XBT: {xbt:.3f}'),\n",
    "            mpatches.Patch(color='yellow', label=f'USD: {usd:.3f}')\n",
    "        ]\n",
    "        \n",
    "        main_legend = plt.legend(loc=1)\n",
    "        plt.legend(handles=patches, loc=2)\n",
    "        plt.gca().add_artist(main_legend)\n",
    "        \n",
    "        plt.title(ob_file.split('/')[-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "condition = DecisionCondition(110000.0, 3000.0)\n",
    "model: DuelingDQN = DuelingDQN(input_dim=47, output_dim=25)\n",
    "target: DuelingDQN = DuelingDQN(input_dim=47, output_dim=25)\n",
    "\n",
    "# model.load_state_dict(torch.load('model-latest.pth'))\n",
    "model.train()\n",
    "target.eval()\n",
    "target.load_state_dict(model.state_dict())\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "target.to(device)\n",
    "agent = Agent(model, target, condition, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = 'notebooks/time-sampled-10min'\n",
    "ob_files = glob.glob(f'{dst_dir}/orderbook_*')\n",
    "tr_files = glob.glob(f'{dst_dir}/trade_*')\n",
    "ob_files, tr_files = map(sorted, [ob_files, tr_files])\n",
    "\n",
    "pairs = list(zip(ob_files, tr_files))\n",
    "outputs: List[SimulatedOrdersOutput] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import notebook\n",
    "total = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4912ad4ba0234f41a93d4d8f05e1bf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in notebook.tqdm(range(total)):\n",
    "    try:\n",
    "        output_required = True if total - 20 < idx else False\n",
    "        ob_file, tr_file = random.choice(pairs)\n",
    "        output = init_simulation(agent, ob_file, tr_file, output_required=output_required, delay=1)\n",
    "        agent.episode_files.append((ob_file, tr_file))\n",
    "        outputs.append(output)\n",
    "    except RuntimeError as e:\n",
    "        print(ob_file, tr_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ob_file</th>\n",
       "      <th>tr_file</th>\n",
       "      <th>usd</th>\n",
       "      <th>xbt</th>\n",
       "      <th>eth</th>\n",
       "      <th>xbt_price</th>\n",
       "      <th>pnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_2046.cs...</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_2046.csv.gz</td>\n",
       "      <td>-26508.75</td>\n",
       "      <td>4.036250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6561.25</td>\n",
       "      <td>-25.905206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_338.csv.gz</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_338.csv.gz</td>\n",
       "      <td>-38967.75</td>\n",
       "      <td>8.932549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4413.00</td>\n",
       "      <td>451.588417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_309.csv.gz</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_309.csv.gz</td>\n",
       "      <td>-9546.25</td>\n",
       "      <td>1.573572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6082.75</td>\n",
       "      <td>25.397715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_1376.cs...</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_1376.csv.gz</td>\n",
       "      <td>-5508.75</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6320.75</td>\n",
       "      <td>85.612958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_1237.cs...</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_1237.csv.gz</td>\n",
       "      <td>4738.50</td>\n",
       "      <td>-0.871838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5407.75</td>\n",
       "      <td>23.819393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_38.csv.gz</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_38.csv.gz</td>\n",
       "      <td>-14649.50</td>\n",
       "      <td>1.848256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7926.25</td>\n",
       "      <td>0.236560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_922.csv.gz</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_922.csv.gz</td>\n",
       "      <td>6999.50</td>\n",
       "      <td>-1.418524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4913.25</td>\n",
       "      <td>29.937738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_1189.cs...</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_1189.csv.gz</td>\n",
       "      <td>-33123.25</td>\n",
       "      <td>6.373520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5218.25</td>\n",
       "      <td>135.373162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_459.csv.gz</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_459.csv.gz</td>\n",
       "      <td>143794.00</td>\n",
       "      <td>-29.029196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5056.75</td>\n",
       "      <td>-2999.384658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>notebooks/time-sampled-10min/orderbook_833.csv.gz</td>\n",
       "      <td>notebooks/time-sampled-10min/trade_833.csv.gz</td>\n",
       "      <td>-11924.00</td>\n",
       "      <td>2.505014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4798.75</td>\n",
       "      <td>96.938093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1801 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ob_file  \\\n",
       "0     notebooks/time-sampled-10min/orderbook_2046.cs...   \n",
       "1     notebooks/time-sampled-10min/orderbook_338.csv.gz   \n",
       "2     notebooks/time-sampled-10min/orderbook_309.csv.gz   \n",
       "3     notebooks/time-sampled-10min/orderbook_1376.cs...   \n",
       "4     notebooks/time-sampled-10min/orderbook_1237.cs...   \n",
       "...                                                 ...   \n",
       "1796   notebooks/time-sampled-10min/orderbook_38.csv.gz   \n",
       "1797  notebooks/time-sampled-10min/orderbook_922.csv.gz   \n",
       "1798  notebooks/time-sampled-10min/orderbook_1189.cs...   \n",
       "1799  notebooks/time-sampled-10min/orderbook_459.csv.gz   \n",
       "1800  notebooks/time-sampled-10min/orderbook_833.csv.gz   \n",
       "\n",
       "                                             tr_file        usd        xbt  \\\n",
       "0     notebooks/time-sampled-10min/trade_2046.csv.gz  -26508.75   4.036250   \n",
       "1      notebooks/time-sampled-10min/trade_338.csv.gz  -38967.75   8.932549   \n",
       "2      notebooks/time-sampled-10min/trade_309.csv.gz   -9546.25   1.573572   \n",
       "3     notebooks/time-sampled-10min/trade_1376.csv.gz   -5508.75   0.885079   \n",
       "4     notebooks/time-sampled-10min/trade_1237.csv.gz    4738.50  -0.871838   \n",
       "...                                              ...        ...        ...   \n",
       "1796    notebooks/time-sampled-10min/trade_38.csv.gz  -14649.50   1.848256   \n",
       "1797   notebooks/time-sampled-10min/trade_922.csv.gz    6999.50  -1.418524   \n",
       "1798  notebooks/time-sampled-10min/trade_1189.csv.gz  -33123.25   6.373520   \n",
       "1799   notebooks/time-sampled-10min/trade_459.csv.gz  143794.00 -29.029196   \n",
       "1800   notebooks/time-sampled-10min/trade_833.csv.gz  -11924.00   2.505014   \n",
       "\n",
       "      eth  xbt_price          pnl  \n",
       "0     0.0    6561.25   -25.905206  \n",
       "1     0.0    4413.00   451.588417  \n",
       "2     0.0    6082.75    25.397715  \n",
       "3     0.0    6320.75    85.612958  \n",
       "4     0.0    5407.75    23.819393  \n",
       "...   ...        ...          ...  \n",
       "1796  0.0    7926.25     0.236560  \n",
       "1797  0.0    4913.25    29.937738  \n",
       "1798  0.0    5218.25   135.373162  \n",
       "1799  0.0    5056.75 -2999.384658  \n",
       "1800  0.0    4798.75    96.938093  \n",
       "\n",
       "[1801 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = agent.episode_results()\n",
    "res['pnl'] = res['usd'] + res['xbt'] * res['xbt_price']\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('latest-result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "positives = res[1000:][res.pnl > 0]\n",
    "negatives = res[1000:][res.pnl < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives sum: 50544.6360; \n",
      "Negatives sum: -82885.3637; \n",
      "Positives max: 2840.4839; \n",
      "Negatives min: -5675.0746\n"
     ]
    }
   ],
   "source": [
    "pos_sum, neg_sum = positives.pnl.sum(), negatives.pnl.sum()\n",
    "pos_max, neg_min = positives.pnl.max(), negatives.pnl.min()\n",
    "print(f'Positives sum: {pos_sum:.4f}; '   +\n",
    "      f'\\nNegatives sum: {neg_sum:.4f}; ' +\n",
    "      f'\\nPositives max: {pos_max:.4f}; ' +\n",
    "      f'\\nNegatives min: {neg_min:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>514.000000</td>\n",
       "      <td>276.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.335868</td>\n",
       "      <td>300.309289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>198.486469</td>\n",
       "      <td>819.333630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.148118</td>\n",
       "      <td>0.074684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.750730</td>\n",
       "      <td>13.480397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.176960</td>\n",
       "      <td>50.434805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>95.738494</td>\n",
       "      <td>151.256356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2840.483897</td>\n",
       "      <td>5675.074558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          positive     negative\n",
       "count   514.000000   276.000000\n",
       "mean     98.335868   300.309289\n",
       "std     198.486469   819.333630\n",
       "min       0.148118     0.074684\n",
       "25%      18.750730    13.480397\n",
       "50%      42.176960    50.434805\n",
       "75%      95.738494   151.256356\n",
       "max    2840.483897  5675.074558"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.concat([positives.pnl, -negatives.pnl], axis=1)\n",
    "summary.columns = ['positive', 'negative']\n",
    "summary.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
